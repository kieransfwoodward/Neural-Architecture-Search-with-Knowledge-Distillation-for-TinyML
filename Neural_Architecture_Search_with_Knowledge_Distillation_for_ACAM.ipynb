{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c8dc72f-b0cb-4dca-8640-a4c0564a66a0",
      "metadata": {
        "editable": true,
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "5c8dc72f-b0cb-4dca-8640-a4c0564a66a0"
      },
      "source": [
        "# Neural Architecture Search with Knowledge Distillation for ACAM\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook implements a Neural Architecture Search (NAS) framework combined with Knowledge Distillation, aimed at finding efficient model architectures for TinyML applications. The primary goal is to discover compact, high-performing neural network architectures that can be deployed on resource-constrained devices.\n",
        "\n",
        "Key components and techniques:\n",
        "\n",
        "1. **Neural Architecture Search (NAS)**: Systematically explores various model architectures, focusing on configurations suitable for small devices.\n",
        "\n",
        "2. **Knowledge Distillation**: Utilises a larger, pre-trained teacher model to guide the training of smaller student models, potentially improving their performance.\n",
        "\n",
        "3. **Model Pruning**: Applies network pruning to reduce model size and potentially improve generalization.\n",
        "\n",
        "4. **Quantization**: Implements quantization to further reduce model size and improve inference speed.\n",
        "\n",
        "5. **CIFAR-10 Dataset**: Uses the CIFAR-10 dataset (converted to grayscale) as a benchmark for evaluating model performance.\n",
        "\n",
        "6. **Efficiency Metrics**: Considers both model accuracy and size to identify the best architectures for TinyML applications.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e3f1eb-72ee-443d-9d71-5e7244f96f4e",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "34e3f1eb-72ee-443d-9d71-5e7244f96f4e"
      },
      "source": [
        "# Setup and Imports\n",
        "\n",
        "This cell imports the necessary libraries and modules for our neural architecture search (NAS) with knowledge distillation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51dbcb19-4fbe-46aa-94c1-e316dd1a5cc4",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "51dbcb19-4fbe-46aa-94c1-e316dd1a5cc4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import itertools\n",
        "import tempfile\n",
        "import os\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from joblib import Parallel, delayed\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96084b14-a103-4c83-a969-957fd6790c10",
      "metadata": {
        "id": "96084b14-a103-4c83-a969-957fd6790c10"
      },
      "source": [
        "# Distiller Class\n",
        "\n",
        "This class implements the knowledge distillation process. It combines the loss from the student model's predictions and the distillation loss from comparing the student's softened predictions to the teacher's softened predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd1233b1",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "cd1233b1"
      },
      "outputs": [],
      "source": [
        "# Distiller class\n",
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super().__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(self, optimizer, metrics, student_loss_fn, distillation_loss_fn, alpha=0.1, temperature=3):\n",
        "        super().compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "        with tf.GradientTape() as tape:\n",
        "            student_predictions = self.student(x, training=True)\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf.nn.softmax(student_predictions / self.temperature, axis=1)\n",
        "            ) * (self.temperature ** 2)\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        return self.student(inputs, training=training)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc9b4358-74fc-4882-962d-4b7db9e8bfac",
      "metadata": {
        "id": "dc9b4358-74fc-4882-962d-4b7db9e8bfac"
      },
      "source": [
        "# Search Space Definition\n",
        "\n",
        "Here we define the possible layers and parameters that our neural architecture search will explore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92edd914",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "92edd914"
      },
      "outputs": [],
      "source": [
        "# Define the search space\n",
        "layer_types = ['Conv2D', 'Dense', 'Flatten', 'MaxPool2D', 'GlobalAveragePooling2D']\n",
        "conv_filters = [16, 32, 64]\n",
        "dense_units = [64, 128, 256]\n",
        "max_layers = 5\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "245d10e5-70ce-470f-b394-94baafe3f1c4",
      "metadata": {
        "id": "245d10e5-70ce-470f-b394-94baafe3f1c4"
      },
      "source": [
        "# Model Creation Function\n",
        "\n",
        "This function creates a Keras model based on a given configuration. It ensures that the model structure is valid, handling the transition from convolutional to dense layers appropriately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adb5286b",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "adb5286b"
      },
      "outputs": [],
      "source": [
        "# Function to create a model given a configuration\n",
        "def create_model(config, input_shape, num_classes, add_softmax=False):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.Input(shape=input_shape))\n",
        "\n",
        "    has_flattened = False\n",
        "    for layer in config[:-1]:  # Process all layers except the last one\n",
        "        if layer[0] == 'Conv2D':\n",
        "            if has_flattened:\n",
        "                continue\n",
        "            model.add(keras.layers.Conv2D(layer[1], (3, 3), activation='relu', padding='same'))\n",
        "        elif layer[0] == 'Dense':\n",
        "            if not has_flattened:\n",
        "                model.add(keras.layers.Flatten())\n",
        "                has_flattened = True\n",
        "            model.add(keras.layers.Dense(layer[1], activation='relu'))\n",
        "        elif layer[0] == 'Flatten':\n",
        "            if not has_flattened:\n",
        "                model.add(keras.layers.Flatten())\n",
        "                has_flattened = True\n",
        "        elif layer[0] == 'MaxPool2D':\n",
        "            if not has_flattened:\n",
        "                model.add(keras.layers.MaxPool2D((2, 2)))\n",
        "        elif layer[0] == 'GlobalAveragePooling2D':\n",
        "            if not has_flattened:\n",
        "                model.add(keras.layers.GlobalAveragePooling2D())\n",
        "                has_flattened = True\n",
        "\n",
        "    # Ensure the model is flattened before the final layer\n",
        "    if not has_flattened:\n",
        "        model.add(keras.layers.Flatten())\n",
        "\n",
        "    # Final layer\n",
        "    if add_softmax:\n",
        "        model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
        "#     else:\n",
        "#         model.add(keras.layers.Dense(num_classes))\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93db3b4e-3f70-4ca6-9dc0-6ada5ac546a8",
      "metadata": {
        "id": "93db3b4e-3f70-4ca6-9dc0-6ada5ac546a8"
      },
      "source": [
        "# ACAM functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e62ef4ce",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "e62ef4ce"
      },
      "outputs": [],
      "source": [
        "# ACAM functions\n",
        "def normalize_similarity(similarities):\n",
        "    min_sim = min(s['similarity'] for s in similarities.values())\n",
        "    max_sim = max(s['similarity'] for s in similarities.values())\n",
        "    for key in similarities:\n",
        "        similarities[key]['normalized_similarity'] = (similarities[key]['similarity'] - min_sim) / (max_sim - min_sim)\n",
        "    return similarities\n",
        "\n",
        "def acam_match_window_search(templates, query):\n",
        "    similarities = {}\n",
        "    for key, value in templates.items():\n",
        "        center = value[\"center\"]\n",
        "        lower_bounds = value[\"lower_bounds\"]\n",
        "        upper_bounds = value[\"upper_bounds\"]\n",
        "\n",
        "        in_range = (query >= lower_bounds) & (query <= upper_bounds)\n",
        "        hit_ratio = np.mean(in_range)\n",
        "\n",
        "        distance = np.sum(np.square(np.clip(lower_bounds - query, 0, None)) +\n",
        "                          np.square(np.clip(query - upper_bounds, 0, None)))\n",
        "\n",
        "        similarity = 1 / (1 + distance)\n",
        "        similarities[key] = {\"similarity\": similarity, \"distance\": distance, \"hit_ratio\": hit_ratio}\n",
        "\n",
        "    return similarities\n",
        "\n",
        "def generate_binary_templates_with_bounds(feature_maps, labels, num_classes, bound_width=0.5, threshold=0.0):\n",
        "    binary_feature_maps = (feature_maps > threshold).astype(int)\n",
        "    templates = {}\n",
        "\n",
        "    for class_idx in range(num_classes):\n",
        "        class_mask = np.argmax(labels, axis=1) == class_idx\n",
        "        class_feature_maps = binary_feature_maps[class_mask]\n",
        "\n",
        "        if len(class_feature_maps) == 0:\n",
        "            continue\n",
        "\n",
        "        center = np.round(np.mean(class_feature_maps, axis=0)).astype(int)\n",
        "        std_dev = np.std(class_feature_maps, axis=0)\n",
        "\n",
        "        lower_bounds = np.clip(center - bound_width * std_dev, 0, 1)\n",
        "        upper_bounds = np.clip(center + bound_width * std_dev, 0, 1)\n",
        "\n",
        "        templates[(class_idx, 0)] = {\n",
        "            \"center\": center,\n",
        "            \"lower_bounds\": lower_bounds,\n",
        "            \"upper_bounds\": upper_bounds\n",
        "        }\n",
        "\n",
        "    return templates\n",
        "\n",
        "def extract_features(model, x):\n",
        "    return model.predict(x)\n",
        "\n",
        "def extract_feature_maps(interpreter, input_details, output_details, input_data):\n",
        "    input_shape = input_details[0]['shape']\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    return output_data\n",
        "\n",
        "def feature_count_matching(templates, query):\n",
        "    match_counts = {}\n",
        "    for key, value in templates.items():\n",
        "        center = value[\"center\"]\n",
        "        count = np.sum(query == center)\n",
        "        match_counts[key] = {\"count\": count, \"class\": key[0]}\n",
        "    return match_counts\n",
        "\n",
        "def extract_feature_map_parallel(model, x_train_sample, idx):\n",
        "    print(f\"Extracting feature map for training sample {idx + 1}/{len(x_train)}\")\n",
        "    return extract_features(model, x_train_sample[np.newaxis, ...])\n",
        "\n",
        "def binarize_features(features, threshold=0.0):\n",
        "    return (features > threshold).astype(int)\n",
        "\n",
        "def pattern_match(binary_features, templates):\n",
        "    similarities = acam_match_window_search(templates, binary_features)\n",
        "    return max(similarities, key=lambda k: similarities[k]['similarity'])[0]\n",
        "\n",
        "def evaluate_with_pattern_matching(model, templates, x_val, y_val):\n",
        "    correct_predictions = 0\n",
        "    for x, y in zip(x_val, y_val):\n",
        "        features = extract_features(model, x[np.newaxis, ...])\n",
        "        binary_features = binarize_features(features[0])\n",
        "        predicted_class = pattern_match(binary_features, templates)\n",
        "        if predicted_class == np.argmax(y):\n",
        "            correct_predictions += 1\n",
        "    return correct_predictions / len(y_val)\n",
        "\n",
        "def quick_evaluate(model, x_train, y_train, x_val, y_val, epochs=5, patience=2):\n",
        "    early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience)\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_val, y_val),\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "    return history.history['val_accuracy'][-1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31e359cf-34f5-4eab-a734-8ec873f27e6e",
      "metadata": {
        "id": "31e359cf-34f5-4eab-a734-8ec873f27e6e"
      },
      "source": [
        "# Neural Architecture Search Function\n",
        "\n",
        "This function performs a comprehensive neural architecture search with knowledge distillation, pruning, and quantization.\n",
        "\n",
        "1. Search Space Definition:\n",
        "   - Defines the range of architectural choices (e.g., number of convolutional blocks, layers per block, initial filters, dense layers).\n",
        "\n",
        "2. Data Splitting:\n",
        "   - Splits the training data to create a smaller subset for quick evaluation.\n",
        "\n",
        "3. Architecture Generation:\n",
        "   - Iterates through different combinations of architectural parameters to generate various model configurations.\n",
        "\n",
        "4. Quick Evaluation:\n",
        "   - For each generated architecture, performs a rapid evaluation using a subset of the data.\n",
        "   - This step helps to quickly filter out poorly performing architectures without spending time on full training.\n",
        "\n",
        "5. Knowledge Distillation:\n",
        "   - For promising architectures (those passing the quick evaluation threshold), applies knowledge distillation.\n",
        "   - Uses a pre-trained teacher model to guide the training of the student (generated) model.\n",
        "   - Combines the standard cross-entropy loss with a distillation loss that encourages the student to mimic the teacher's softened outputs.\n",
        "\n",
        "6. Pruning:\n",
        "   - Applies network pruning to reduce model size and potentially improve generalization.\n",
        "   - Uses polynomial decay pruning schedule, gradually increasing sparsity over time.\n",
        "\n",
        "7. Quantization:\n",
        "   - Applies quantization to further reduce model size and improve inference speed.\n",
        "   - Converts the model to TensorFlow Lite format with default optimizations.\n",
        "\n",
        "8. Final Evaluation:\n",
        "   - Assesses the pruned and quantized model on the test set to get the final accuracy.\n",
        "\n",
        "9. Model Tracking:\n",
        "   - Keeps track of the top 5 models based on accuracy and model size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3940eb09",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "3940eb09"
      },
      "outputs": [],
      "source": [
        "def search_architectures(x_train, y_train, x_test, y_test, input_shape, num_classes, teacher):\n",
        "    best_models = deque(maxlen=5)\n",
        "\n",
        "    # Define the search space\n",
        "    conv_blocks = [1, 2, 3]\n",
        "    conv_layers_per_block = [1, 2]\n",
        "    initial_filters = [16, 32, 64]\n",
        "    dense_layers = [0, 1, 2, 3]\n",
        "    dense_units_options = [64, 128, 256, 512]\n",
        "\n",
        "    total_configs = len(conv_blocks) * len(conv_layers_per_block) * len(initial_filters) * len(dense_layers) * len(dense_units_options)\n",
        "    config_count = 0\n",
        "\n",
        "    for n_blocks in conv_blocks:\n",
        "        for layers_per_block in conv_layers_per_block:\n",
        "            for init_filters in initial_filters:\n",
        "                for n_dense in dense_layers:\n",
        "                    for dense_units in dense_units_options:\n",
        "                        config_count += 1\n",
        "                        print(f\"\\nTesting configuration {config_count}/{total_configs}\")\n",
        "\n",
        "                        # Build the model configuration\n",
        "                        config = []\n",
        "                        filters = init_filters\n",
        "                        for _ in range(n_blocks):\n",
        "                            for _ in range(layers_per_block):\n",
        "                                config.append(('Conv2D', filters))\n",
        "                            config.append(('MaxPool2D', None))\n",
        "                            filters *= 2\n",
        "\n",
        "                        config.append(('GlobalAveragePooling2D', None))\n",
        "\n",
        "                        for _ in range(n_dense):\n",
        "                            config.append(('Dense', dense_units))\n",
        "                            dense_units = max(dense_units // 2, 64)\n",
        "\n",
        "                        # Add final layer\n",
        "#                         config.append(('Dense', num_classes))\n",
        "\n",
        "                        try:\n",
        "                            # Create model with softmax for quick evaluation\n",
        "                            student = create_model(config, input_shape, num_classes, add_softmax=True)\n",
        "                            student.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "                        except:\n",
        "                            print(\"Failed to create model with this configuration. Skipping...\")\n",
        "                            continue\n",
        "\n",
        "                        # Quick evaluation with softmax\n",
        "                        quick_accuracy = quick_evaluate(student, x_train, y_train, x_test, y_test)\n",
        "                        print(f\"Quick evaluation accuracy: {quick_accuracy:.4f}\")\n",
        "\n",
        "                        if quick_accuracy < 0.7:\n",
        "                            print(\"Accuracy below threshold. Skipping...\")\n",
        "                            continue\n",
        "\n",
        "                        # Create model without softmax for further processing\n",
        "                        student = create_model(config, input_shape, num_classes, add_softmax=False)\n",
        "\n",
        "#                         New\n",
        "                        student.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "                        student.fit(x_train, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
        "\n",
        "\n",
        "                        # Apply knowledge distillation\n",
        "                        distiller = Distiller(student=student, teacher=teacher)\n",
        "                        distiller.compile(\n",
        "                            optimizer=keras.optimizers.Adam(),\n",
        "                            metrics=[keras.metrics.MeanSquaredError()],\n",
        "                            student_loss_fn=keras.losses.MeanSquaredError(),\n",
        "                            distillation_loss_fn=keras.losses.MeanSquaredError(),\n",
        "                            alpha=0.1,\n",
        "                            temperature=3,\n",
        "                        )\n",
        "                        distiller.fit(x_train, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
        "\n",
        "                        # Apply pruning\n",
        "                        pruning_params = {\n",
        "                            'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
        "                                initial_sparsity=0.30,\n",
        "                                final_sparsity=0.50,\n",
        "                                begin_step=0,\n",
        "                                end_step=len(x_train) * 10\n",
        "                            )\n",
        "                        }\n",
        "                        pruned_model = tfmot.sparsity.keras.prune_low_magnitude(distiller.student, **pruning_params)\n",
        "                        pruned_model.compile(\n",
        "                            optimizer=keras.optimizers.Adam(),\n",
        "                            loss=keras.losses.MeanSquaredError(),\n",
        "                            metrics=[keras.metrics.MeanSquaredError()],\n",
        "                        )\n",
        "                        with tf.device('/cpu:0'):\n",
        "                            pruned_model.fit(x_train, y_train, epochs=1, validation_split=0.2, callbacks=[\n",
        "                                tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "                                tfmot.sparsity.keras.PruningSummaries(log_dir=tempfile.mkdtemp()),\n",
        "                            ], verbose=0)\n",
        "\n",
        "                        # Apply quantization-aware training\n",
        "                        quantize_model = tfmot.quantization.keras.quantize_model\n",
        "                        stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "                        q_aware_model = quantize_model(stripped_pruned_model)\n",
        "\n",
        "                        q_aware_model.compile(\n",
        "                            optimizer=keras.optimizers.Adam(),\n",
        "                            loss=keras.losses.MeanSquaredError(),\n",
        "                            metrics=[keras.metrics.MeanSquaredError()],\n",
        "                        )\n",
        "\n",
        "                        q_aware_model.fit(x_train, y_train, epochs=5, validation_split=0.2, verbose=0)\n",
        "\n",
        "                        # Generate templates and evaluate using pattern matching\n",
        "                        print(\"Generating templates...\")\n",
        "#                         train_features = extract_features(q_aware_model, x_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                        # Extract feature maps for all training samples in parallel\n",
        "\n",
        "\n",
        "                        print(\"Extracting feature maps for all training samples...\")\n",
        "                        train_feature_maps = q_aware_model.predict(x_train)\n",
        "                        train_feature_maps = train_feature_maps.reshape(len(x_train), -1)\n",
        "                        print(\"Feature map extraction completed.\")\n",
        "\n",
        "\n",
        "\n",
        "                        def process_feature_map(feature_map, idx):\n",
        "                            print(f\"Processing feature map for training sample {idx + 1}/{len(x_train)}\")\n",
        "                            return feature_map  # You can add any additional processing here if needed\n",
        "\n",
        "                        print(\"Starting parallel processing of feature maps...\")\n",
        "                        processed_feature_maps = Parallel(n_jobs=-1)(\n",
        "                            delayed(process_feature_map)(train_feature_maps[i], i) for i in range(len(x_train))\n",
        "                        )\n",
        "                        processed_feature_maps = np.array(processed_feature_maps)\n",
        "                        print(\"Parallel processing of feature maps completed.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                        templates = generate_binary_templates_with_bounds(processed_feature_maps, y_train, num_classes, bound_width=0.5)\n",
        "\n",
        "\n",
        "                        print(\"Evaluating with pattern matching...\")\n",
        "\n",
        "\n",
        "                        correct_predictions_similarity = 0\n",
        "                        correct_predictions_count = 0\n",
        "                        num_test_samples = len(x_test)\n",
        "                        class_correct = defaultdict(int)\n",
        "                        class_total = defaultdict(int)\n",
        "                        true_labels = []\n",
        "                        predicted_labels = []\n",
        "\n",
        "\n",
        "\n",
        "                        print(\"Starting testing on test samples...\")\n",
        "                        for i in range(num_test_samples):\n",
        "                            test_sample_feature_map = extract_features(q_aware_model, x_test[i][np.newaxis, ...])\n",
        "                            test_sample_vector = test_sample_feature_map.flatten()\n",
        "\n",
        "                            # Binarize the test sample\n",
        "                            binary_test_sample = (test_sample_vector > 0).astype(int)\n",
        "\n",
        "                            # Similarity-based method\n",
        "                            similarities = acam_match_window_search(templates, binary_test_sample)\n",
        "\n",
        "                            predicted_template_similarity = max(similarities, key=lambda k: similarities[k]['similarity'])[0]\n",
        "                            predicted_label_similarity = predicted_template_similarity\n",
        "\n",
        "                            # Feature count method\n",
        "                            match_counts = feature_count_matching(templates, binary_test_sample)\n",
        "                            predicted_template_count = max(match_counts, key=lambda k: match_counts[k]['count'])\n",
        "                            predicted_label_count = match_counts[predicted_template_count]['class']\n",
        "\n",
        "                            true_label = y_test[i].argmax()\n",
        "                            class_total[true_label] += 1\n",
        "\n",
        "                            if predicted_label_similarity == true_label:\n",
        "                                class_correct[true_label] += 1\n",
        "                                correct_predictions_similarity += 1\n",
        "\n",
        "                            if predicted_label_count == true_label:\n",
        "                                correct_predictions_count += 1\n",
        "\n",
        "                            true_labels.append(true_label)\n",
        "                            predicted_labels.append(predicted_label_similarity)\n",
        "\n",
        "                            print(f\"Test sample {i + 1}/{num_test_samples}:\")\n",
        "                            print(f\"True label: {true_label}\")\n",
        "                            print(f\"Predicted label (similarity): {predicted_label_similarity}\")\n",
        "                            print(f\"Predicted label (feature count): {predicted_label_count}\")\n",
        "\n",
        "                        accuracy_similarity = correct_predictions_similarity / num_test_samples\n",
        "                        accuracy_count = correct_predictions_count / num_test_samples\n",
        "                        print(\"Testing completed.\")\n",
        "                        print(f\"Accuracy (similarity-based): {accuracy_similarity:.4f}\")\n",
        "                        print(f\"Accuracy (feature count-based): {accuracy_count:.4f}\")\n",
        "\n",
        "#                         accuracy = evaluate_with_pattern_matching(q_aware_model, templates, x_test, y_test)\n",
        "\n",
        "                        # Convert to TFLite\n",
        "                        converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "                        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "                        quantized_tflite_model = converter.convert()\n",
        "\n",
        "                        # Save and get model size\n",
        "                        _, tflite_file = tempfile.mkstemp('.tflite')\n",
        "                        with open(tflite_file, 'wb') as f:\n",
        "                            f.write(quantized_tflite_model)\n",
        "\n",
        "                        model_size = os.path.getsize(tflite_file) / float(2**20)  # Size in MB\n",
        "                        num_params = q_aware_model.count_params()\n",
        "\n",
        "                        print(f\"Configuration: {config}\")\n",
        "                        print(f\"Pattern matching accuracy: {accuracy_count:.4f}\")\n",
        "                        print(f\"Model size: {model_size:.2f} MB\")\n",
        "                        print(f\"Number of parameters: {num_params}\")\n",
        "                        print(\"--------------------\")\n",
        "\n",
        "                        best_models.append((q_aware_model, accuracy_count, model_size, num_params, config))\n",
        "                        best_models = deque(sorted(best_models, key=lambda x: (x[1], -x[2]), reverse=True)[:5])\n",
        "\n",
        "    return best_models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7a262fc-f16f-43c3-ad08-9a8fc2daeeee",
      "metadata": {
        "id": "d7a262fc-f16f-43c3-ad08-9a8fc2daeeee"
      },
      "source": [
        "# Data Preparation and Teacher Model Creation\n",
        "\n",
        "This section loads and preprocesses the CIFAR-10 dataset, converting it to grayscale. It also defines and trains the teacher model that will be used for knowledge distillation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57871b35",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "57871b35"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Convert images to greyscale\n",
        "x_train = np.dot(x_train[..., :3], [0.2989, 0.5870, 0.1140])\n",
        "x_test = np.dot(x_test[..., :3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "# Normalize and reshape\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_train = np.reshape(x_train, (-1, 32, 32, 1))\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_test = np.reshape(x_test, (-1, 32, 32, 1))\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Use only 1000 samples for training and testing\n",
        "x_train, _, y_train, _ = train_test_split(x_train, y_train, stratify=y_train, random_state=42)\n",
        "x_test, _, y_test, _ = train_test_split(x_test, y_test, stratify=y_test, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "964a0879",
      "metadata": {
        "id": "964a0879",
        "outputId": "c86cc1f5-3054-4a4c-c7bf-207851805537"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "938/938 [==============================] - 32s 26ms/step - loss: 2.0092 - accuracy: 0.2710 - val_loss: 1.6231 - val_accuracy: 0.4287\n",
            "Epoch 2/20\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 1.4778 - accuracy: 0.4830 - val_loss: 1.2387 - val_accuracy: 0.5721\n",
            "Epoch 3/20\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 1.2098 - accuracy: 0.5937 - val_loss: 1.0165 - val_accuracy: 0.6553\n",
            "Epoch 4/20\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 1.0362 - accuracy: 0.6547 - val_loss: 0.9305 - val_accuracy: 0.6872\n",
            "Epoch 5/20\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.9243 - accuracy: 0.6939 - val_loss: 0.8542 - val_accuracy: 0.7175\n",
            "Epoch 6/20\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.8414 - accuracy: 0.7217 - val_loss: 0.8322 - val_accuracy: 0.7295\n",
            "Epoch 7/20\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.7811 - accuracy: 0.7414 - val_loss: 0.8075 - val_accuracy: 0.7295\n",
            "Epoch 8/20\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.7189 - accuracy: 0.7631 - val_loss: 0.7614 - val_accuracy: 0.7516\n",
            "Epoch 9/20\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.6724 - accuracy: 0.7809 - val_loss: 0.7630 - val_accuracy: 0.7477\n",
            "Epoch 10/20\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.6272 - accuracy: 0.7912 - val_loss: 0.7513 - val_accuracy: 0.7552\n",
            "Epoch 11/20\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.5851 - accuracy: 0.8081 - val_loss: 0.6997 - val_accuracy: 0.7797\n",
            "Epoch 12/20\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.5528 - accuracy: 0.8171 - val_loss: 0.7697 - val_accuracy: 0.7619\n",
            "Epoch 13/20\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.5137 - accuracy: 0.8288 - val_loss: 0.7331 - val_accuracy: 0.7821\n",
            "Epoch 14/20\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.4789 - accuracy: 0.8430 - val_loss: 0.7644 - val_accuracy: 0.7733\n",
            "Epoch 15/20\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.4458 - accuracy: 0.8527 - val_loss: 0.7543 - val_accuracy: 0.7748\n",
            "Epoch 16/20\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.4218 - accuracy: 0.8621 - val_loss: 0.7514 - val_accuracy: 0.7841\n",
            "Epoch 17/20\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.3999 - accuracy: 0.8688 - val_loss: 0.7559 - val_accuracy: 0.7809\n",
            "Epoch 18/20\n",
            "938/938 [==============================] - 29s 30ms/step - loss: 0.3799 - accuracy: 0.8764 - val_loss: 0.7620 - val_accuracy: 0.7841\n",
            "Epoch 19/20\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.3600 - accuracy: 0.8841 - val_loss: 0.7602 - val_accuracy: 0.7833\n",
            "Epoch 20/20\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 0.3521 - accuracy: 0.8869 - val_loss: 0.7597 - val_accuracy: 0.7825\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x155dbc03760>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the teacher model\n",
        "teacher = keras.Sequential([\n",
        "    keras.Input(shape=(32, 32, 1)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation='relu', kernel_initializer='he_uniform'),\n",
        "    keras.layers.Dense(256, activation='relu', kernel_initializer='he_uniform'),\n",
        "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compile and train the teacher\n",
        "teacher.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "teacher.fit(x_train, y_train, epochs=20, validation_split=0.2, verbose=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5f2775c",
      "metadata": {
        "scrolled": true,
        "id": "d5f2775c",
        "outputId": "5d18defb-aa2f-4769-e55f-2e6667654c87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing configuration 1/288\n",
            "Quick evaluation accuracy: 0.5391\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 2/288\n",
            "Quick evaluation accuracy: 0.5215\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 3/288\n",
            "Quick evaluation accuracy: 0.5368\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 4/288\n",
            "Quick evaluation accuracy: 0.5204\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 5/288\n",
            "Quick evaluation accuracy: 0.2244\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 6/288\n",
            "Quick evaluation accuracy: 0.2093\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 7/288\n",
            "Quick evaluation accuracy: 0.2143\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 8/288\n",
            "Quick evaluation accuracy: 0.2369\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 9/288\n",
            "Quick evaluation accuracy: 0.2853\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 10/288\n",
            "Quick evaluation accuracy: 0.2845\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 11/288\n",
            "Quick evaluation accuracy: 0.2923\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 12/288\n",
            "Quick evaluation accuracy: 0.3043\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 13/288\n",
            "Quick evaluation accuracy: 0.3031\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 14/288\n",
            "Quick evaluation accuracy: 0.3069\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 15/288\n",
            "Quick evaluation accuracy: 0.2957\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 16/288\n",
            "Quick evaluation accuracy: 0.3007\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 17/288\n",
            "Quick evaluation accuracy: 0.5608\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 18/288\n",
            "Quick evaluation accuracy: 0.5637\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 19/288\n",
            "Quick evaluation accuracy: 0.5572\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 20/288\n",
            "Quick evaluation accuracy: 0.5604\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 21/288\n",
            "Quick evaluation accuracy: 0.2640\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 22/288\n",
            "Quick evaluation accuracy: 0.2512\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 23/288\n",
            "Quick evaluation accuracy: 0.2463\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 24/288\n",
            "Quick evaluation accuracy: 0.2036\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 25/288\n",
            "Quick evaluation accuracy: 0.2924\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 26/288\n",
            "Quick evaluation accuracy: 0.2985\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 27/288\n",
            "Quick evaluation accuracy: 0.2932\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 28/288\n",
            "Quick evaluation accuracy: 0.3160\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 29/288\n",
            "Quick evaluation accuracy: 0.3096\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 30/288\n",
            "Quick evaluation accuracy: 0.3103\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 31/288\n",
            "Quick evaluation accuracy: 0.3243\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 32/288\n",
            "Quick evaluation accuracy: 0.3496\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 33/288\n",
            "Quick evaluation accuracy: 0.5685\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 34/288\n",
            "Quick evaluation accuracy: 0.5804\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 35/288\n",
            "Quick evaluation accuracy: 0.5791\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 36/288\n",
            "Quick evaluation accuracy: 0.5635\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 37/288\n",
            "Quick evaluation accuracy: 0.2747\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 38/288\n",
            "Quick evaluation accuracy: 0.2776\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 39/288\n",
            "Quick evaluation accuracy: 0.2536\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 40/288\n",
            "Quick evaluation accuracy: 0.2628\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 41/288\n",
            "Quick evaluation accuracy: 0.3088\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 42/288\n",
            "Quick evaluation accuracy: 0.3156\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 43/288\n",
            "Quick evaluation accuracy: 0.3001\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 44/288\n",
            "Quick evaluation accuracy: 0.3407\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 45/288\n",
            "Quick evaluation accuracy: 0.3196\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 46/288\n",
            "Quick evaluation accuracy: 0.2997\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 47/288\n",
            "Quick evaluation accuracy: 0.3333\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 48/288\n",
            "Quick evaluation accuracy: 0.3237\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 49/288\n",
            "Quick evaluation accuracy: 0.6064\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 50/288\n",
            "Quick evaluation accuracy: 0.5899\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 51/288\n",
            "Quick evaluation accuracy: 0.5760\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 52/288\n",
            "Quick evaluation accuracy: 0.5968\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 53/288\n",
            "Quick evaluation accuracy: 0.3197\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 54/288\n",
            "Quick evaluation accuracy: 0.2889\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 55/288\n",
            "Quick evaluation accuracy: 0.3201\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 56/288\n",
            "Quick evaluation accuracy: 0.3355\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 57/288\n",
            "Quick evaluation accuracy: 0.3371\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 58/288\n",
            "Quick evaluation accuracy: 0.3516\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 59/288\n",
            "Quick evaluation accuracy: 0.3552\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 60/288\n",
            "Quick evaluation accuracy: 0.3468\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 61/288\n",
            "Quick evaluation accuracy: 0.3683\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 62/288\n",
            "Quick evaluation accuracy: 0.3648\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 63/288\n",
            "Quick evaluation accuracy: 0.3849\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 64/288\n",
            "Quick evaluation accuracy: 0.3807\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 65/288\n",
            "Quick evaluation accuracy: 0.6067\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 66/288\n",
            "Quick evaluation accuracy: 0.6127\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 67/288\n",
            "Quick evaluation accuracy: 0.6025\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 68/288\n",
            "Quick evaluation accuracy: 0.6200\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 69/288\n",
            "Quick evaluation accuracy: 0.3491\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 70/288\n",
            "Quick evaluation accuracy: 0.3611\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 71/288\n",
            "Quick evaluation accuracy: 0.3544\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 72/288\n",
            "Quick evaluation accuracy: 0.3465\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 73/288\n",
            "Quick evaluation accuracy: 0.3676\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 74/288\n",
            "Quick evaluation accuracy: 0.3972\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 75/288\n",
            "Quick evaluation accuracy: 0.4073\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 76/288\n",
            "Quick evaluation accuracy: 0.4233\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 77/288\n",
            "Quick evaluation accuracy: 0.3744\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 78/288\n",
            "Quick evaluation accuracy: 0.4137\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 79/288\n",
            "Quick evaluation accuracy: 0.4021\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 80/288\n",
            "Quick evaluation accuracy: 0.4272\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 81/288\n",
            "Quick evaluation accuracy: 0.6263\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 82/288\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quick evaluation accuracy: 0.6159\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 83/288\n",
            "Quick evaluation accuracy: 0.6145\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 84/288\n",
            "Quick evaluation accuracy: 0.6197\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 85/288\n",
            "Quick evaluation accuracy: 0.3825\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 86/288\n",
            "Quick evaluation accuracy: 0.3801\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 87/288\n",
            "Quick evaluation accuracy: 0.3849\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 88/288\n",
            "Quick evaluation accuracy: 0.3627\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 89/288\n",
            "Quick evaluation accuracy: 0.4297\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 90/288\n",
            "Quick evaluation accuracy: 0.4333\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 91/288\n",
            "Quick evaluation accuracy: 0.4459\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 92/288\n",
            "Quick evaluation accuracy: 0.4433\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 93/288\n",
            "Quick evaluation accuracy: 0.4345\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 94/288\n",
            "Quick evaluation accuracy: 0.4397\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 95/288\n",
            "Quick evaluation accuracy: 0.4539\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 96/288\n",
            "Quick evaluation accuracy: 0.4696\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 97/288\n",
            "Quick evaluation accuracy: 0.6116\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 98/288\n",
            "Quick evaluation accuracy: 0.6060\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 99/288\n",
            "Quick evaluation accuracy: 0.5903\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 100/288\n",
            "Quick evaluation accuracy: 0.6180\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 101/288\n",
            "Quick evaluation accuracy: 0.3519\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 102/288\n",
            "Quick evaluation accuracy: 0.3577\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 103/288\n",
            "Quick evaluation accuracy: 0.3727\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 104/288\n",
            "Quick evaluation accuracy: 0.3459\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 105/288\n",
            "Quick evaluation accuracy: 0.3760\n",
            "Accuracy below threshold. Skipping...\n",
            "\n",
            "Testing configuration 106/288\n"
          ]
        }
      ],
      "source": [
        "# Run the architecture search\n",
        "best_models = search_architectures(x_train, y_train, x_test, y_test, input_shape=(32, 32, 1), num_classes=num_classes, teacher=teacher)\n",
        "for i, (model, accuracy, size, params, config) in enumerate(best_models, 1):\n",
        "    print(f\"Model {i}:\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  Size: {size:.2f} MB\")\n",
        "    print(f\"  Parameters: {params}\")\n",
        "    print(f\"  Configuration: {config}\")\n",
        "    print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "894876d6-a488-4d14-abf3-471743daca4d",
      "metadata": {
        "id": "894876d6-a488-4d14-abf3-471743daca4d"
      },
      "source": [
        "# Visualisation Function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d0d4b1",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "22d0d4b1"
      },
      "outputs": [],
      "source": [
        "# Visualization function\n",
        "def plot_top_models(top_models):\n",
        "    accuracies = [model[1] for model in top_models]\n",
        "    params = [model[3] for model in top_models]\n",
        "    sizes = [model[2] for model in top_models]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    scatter = plt.scatter(params, accuracies, c=sizes, s=100, cmap='viridis')\n",
        "    plt.colorbar(scatter, label='Model Size (MB)')\n",
        "\n",
        "    plt.xscale('log')\n",
        "    plt.xlabel('Number of Parameters')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Top 5 Models: Accuracy vs Number of Parameters')\n",
        "\n",
        "    for i, model in enumerate(top_models):\n",
        "        plt.annotate(f\"Model {i+1}\", (params[i], accuracies[i]), xytext=(5, 5), textcoords='offset points')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the results\n",
        "plot_top_models(best_models)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e83a07",
      "metadata": {
        "id": "a2e83a07"
      },
      "outputs": [],
      "source": [
        "# Evaluate the best model\n",
        "best_model = best_models[0][0]\n",
        "train_features = extract_features(best_model, x_train)\n",
        "templates = generate_binary_templates_with_bounds(train_features, y_train, num_classes)\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for x, y in zip(x_test, y_test):\n",
        "    features = extract_features(best_model, x[np.newaxis, ...])\n",
        "    binary_features = binarize_features(features[0])\n",
        "    predicted_class = pattern_match(binary_features, templates)\n",
        "    y_true.append(np.argmax(y))\n",
        "    y_pred.append(predicted_class)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edee3eb3",
      "metadata": {
        "id": "edee3eb3"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850a5b7e",
      "metadata": {
        "id": "850a5b7e"
      },
      "outputs": [],
      "source": [
        "# Classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc128ff",
      "metadata": {
        "id": "bbc128ff"
      },
      "outputs": [],
      "source": [
        "# Print top misclassifications\n",
        "def print_top_misclassifications(cm, class_names, top_n=5):\n",
        "    misclassifications = []\n",
        "    for i in range(len(cm)):\n",
        "        for j in range(len(cm)):\n",
        "            if i != j:\n",
        "                misclassifications.append((i, j, cm[i, j]))\n",
        "\n",
        "    misclassifications.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    print(f\"Top {top_n} misclassifications:\")\n",
        "    for true, pred, count in misclassifications[:top_n]:\n",
        "        print(f\"True: {class_names[true]}, Predicted: {class_names[pred]}, Count: {count}\")\n",
        "\n",
        "class_names = [str(i) for i in range(num_classes)]\n",
        "print_top_misclassifications(cm, class_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3cecc97",
      "metadata": {
        "id": "c3cecc97"
      },
      "outputs": [],
      "source": [
        "# Plot accuracy by class\n",
        "class_accuracy = {}\n",
        "for i in range(num_classes):\n",
        "    class_accuracy[i] = cm[i, i] / np.sum(cm[i])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(class_names, list(class_accuracy.values()))\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy by Class')\n",
        "plt.ylim(0, 1)\n",
        "for i, v in enumerate(class_accuracy.values()):\n",
        "    plt.text(i, v + 0.01, f'{v:.2f}', ha='center')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb2e7008",
      "metadata": {
        "id": "eb2e7008"
      },
      "outputs": [],
      "source": [
        "# Template overlap analysis\n",
        "def calculate_template_overlap(templates):\n",
        "    num_classes = len(templates)\n",
        "    overlap_matrix = np.zeros((num_classes, num_classes))\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        for j in range(num_classes):\n",
        "            if (i, 0) not in templates or (j, 0) not in templates:\n",
        "                continue\n",
        "\n",
        "            template_i = templates[(i, 0)]\n",
        "            template_j = templates[(j, 0)]\n",
        "\n",
        "            lower_i, upper_i = template_i['lower_bounds'], template_i['upper_bounds']\n",
        "            lower_j, upper_j = template_j['lower_bounds'], template_j['upper_bounds']\n",
        "\n",
        "            min_upper = np.minimum(upper_i, upper_j)\n",
        "            max_lower = np.maximum(lower_i, lower_j)\n",
        "            overlap = np.maximum(0, min_upper - max_lower)\n",
        "\n",
        "            total_range = np.maximum(upper_i, upper_j) - np.minimum(lower_i, lower_j)\n",
        "            overlap_ratio = np.mean(overlap / (total_range + 1e-10))\n",
        "\n",
        "            overlap_matrix[i, j] = overlap_ratio\n",
        "\n",
        "    return overlap_matrix\n",
        "\n",
        "overlap_matrix = calculate_template_overlap(templates)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(overlap_matrix, annot=True, cmap='YlOrRd', vmin=0, vmax=1, fmt='.2f')\n",
        "plt.title('Overlap between Class Templates')\n",
        "plt.xlabel('Template Class')\n",
        "plt.ylabel('Template Class')\n",
        "plt.show()\n",
        "\n",
        "print(\"Average overlap for each class:\")\n",
        "for i in range(len(overlap_matrix)):\n",
        "    avg_overlap = np.mean(overlap_matrix[i, :])\n",
        "    print(f\"Class {i}: {avg_overlap:.4f}\")\n",
        "\n",
        "print(\"\\nClasses with highest mutual overlap:\")\n",
        "class_pairs = [(i, j) for i in range(len(overlap_matrix)) for j in range(i+1, len(overlap_matrix))]\n",
        "class_pairs.sort(key=lambda x: overlap_matrix[x[0], x[1]], reverse=True)\n",
        "for i, j in class_pairs[:5]:\n",
        "    print(f\"Class {i} and Class {j}: {overlap_matrix[i, j]:.4f}\")\n",
        "\n",
        "avg_overlaps = np.mean(overlap_matrix, axis=1)\n",
        "most_overlapping_class = np.argmax(avg_overlaps)\n",
        "print(f\"\\nClass with highest average overlap: {most_overlapping_class}\")\n",
        "print(f\"Average overlap: {avg_overlaps[most_overlapping_class]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4575c0f4",
      "metadata": {
        "id": "4575c0f4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}